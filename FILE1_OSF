########################################################### PACKAGES & LIBRARIES ####################################################
#####################################################################################################################################

## Install Packages
install.packages("readxl", type ="binary", dependency = TRUE)# To read Excel files
install.packages("openxlsx", type ="binary", dependency = TRUE)# To create Excel files
install.packages("dplyr", type ="binary", dependency = TRUE) # For data manipulation
install.packages("tidyr", type ="binary", dependency = TRUE) # For additional data manipulation
install.packages("psych", type ="binary", dependency = TRUE) # For additional data manipulation
install.packages("ggplot2", type ="binary", dependency = TRUE) # For additional data manipulation
install.packages("corrplot", type ="binary", dependency = TRUE) # For additional data manipulation
install.packages("lavaan", type ="binary", dependency = TRUE)# For additional data manipulation
install.packages("semTools", type ="binary", dependency = TRUE)
install.packages("knitr", type ="binary", dependency = TRUE)
install.packages("kableExtra", type ="binary", dependency = TRUE)
install.packages("GPArotation", type ="binary", dependency = TRUE)
install.packages("factoextra", type ="binary", dependency = TRUE)
install.packages("semPlot", type ="binary", dependency = TRUE)
install.packages("reshape2", type ="binary", dependency = TRUE)
install.packages("Hmisc", type ="binary", dependency = TRUE)
install.packages("circlize", type ="binary", dependency = TRUE)


## Import libraries
library(readxl)
library(openxlsx)
library(dplyr)
library(tidyr)
library(psych)
library(ggplot2)
library(corrplot)
library(lavaan)
library(semTools)
library(knitr)
library(kableExtra)
library(GPArotation)
library(factoextra)
library(semPlot)
library(reshape2)
library(Hmisc)
library(circlize)


#################################################################### CLEAN DATA ###########################################################
###########################################################################################################################################

## Read dataset
data_full <- read_excel("data_compiled.xlsx") #includes all variables


## Select variables that I need based on manual selection of variables related to Livingston et al. (2024)
# Create subset 
data <- subset(data_full, select = c(CCID, Age, age_iv, sex, v1,v5,v13,v14,v16,v18,v73,v74,v75,v86,v87,v89,v90,v91,v92,v93,v94,v95,v96,v97,v98,v106,v108,v241,v242,v244,v245,v246,v247,v249,v251,v252,v253,v255,v256,v257,v259,v260,v261,v290,v291,v292,v293,v294,v295,v296,v297,v298,v326,v327,v328,v329,v330,v331,v332,v333,v334,v335,v336,v337,v338,v339,v340,v341,v342,v343,v344,v345,v346,v347,v349,v350,v352,v352,v353,v354,v355,v356,v377,v378,v422,v457,v458,v459,v460,v542,v543,v544,v545,v620,v621,v624,v626,v627,v629,v630,v632,v633,v634,v639,v640,v668,v669,place,age_iv,smoker,alcohol,HADS_depression,HADS_dep_category,qual,
                                     GETABOUT_bikedist,GETABOUT_walkdist,DURGETABOUT_BIKE, DURGETABOUT_WALK,GETABOUTBIKEadj,GETABOUTWALKadj, DURGETABOUT,DURTV, TVadj, WALKMILES, CYCLEMILES, CARMILES, PUBLICMILES, CARadj, PUBLICadj, CYCLEadj, WALKadj,HOMEtime, WORKtime, DURJOB, COMMUTEtime, LEIStime, UNACCOUNTED_TIME, TOTMETHRS, TOTMETHRS_w_UNACCtime, TOTALtime, ACTMETS, SED_INTENSITY, LIGHT_INTENSITY, MODERATE_INTENSITY,VIGOROUS_INTENSITY, SLEEPtime, SEDtime, LIGHTtime, MODERATEtime, VIGOROUStime, HOME_METS, WORK_METS, LEIS_METS, COMMUTE_METS, leisure_missing_all_data, leisure_missing_freq, leisure_missing_duration, activities_done,PAEE, HOME_PAEE, WORK_PAEE,LEIS_PAEE,COMMUTE_PAEE, 
                                     question_num_years_edu,
                                     height, weight, bp_sys2, bp_sys3,
                                     C1.y,C2.y,C3.y,C4.y,
                                     WMHI_NORM_TIV, FA_mean, MSD_mean,MSK_mean, NDI_mean,ODI_mean, Fiso_mean))
## Subset of subjects that have DWI data
data_dwi <- data[complete.cases(data[, c("FA_mean", "MSD_mean", "MSK_mean", "NDI_mean", "ODI_mean", "Fiso_mean")]), ]

######### TRANSFORM TO NUMERIC DATA ##########
##############################################

## Sex
data_dwi$sex # Print
data_dwi$sex <- ifelse(data_dwi$sex == "F", 1, 0) # Transform (F = 1; M = 0)

## Relationship to Household members  
data_dwi$v14 # Print -> TBD because answers are multiple
'How are the other people who live with you related to you? (YOU CAN SELECT MORE THAN ONE ANSWER) 	0. Not related
1. Husband, wife or partner 
2. Son and/or daughter (include step children) 
3. Brother and/or sister 
4. Mother and/or father 
5. Grandchild 
6. Other related 
7. Do not know
8. No answer 
'
# EXCLUDE - because uncertain how much incremental validity this question brings to social isolation

## Which qualification do you have
data_dwi$v73 # Print -> Multiple answers, replace with "qual"?
# EXCLUDE - replace with "qual" which is only highest qualification and "Years of education" 

## Attend any meetings/groups/classes?
data_dwi$v96 # Print -> TBD, Multiple answers
'
Do you attend meetings of any community, church/mosque or social groups such as WI, evening classes?
  (YOU MAY ANSWER MORE THAN ONE)
EACH QUESTION WILL BE FOLLOWED BY HOW OFTEN RATING	00. No clubs
01. Political parties
02. Trade unions (including student union)
03. Environmental groups
04. Tenants, residents group or neighbourhood watch
05. Evening classes
06. U3A
07. Other adult learning
08. Arts, music or singing group
09. Charity, volunteer or community group
11. Group for the elderly
12. Youth group (guides, scouts, youth club)
13. Women’s Institute
14. Social club (rotary, working men’s)
15. Sports club, gym, exercise group
16. Church/religious group
17. Other group or organisation 
77. Don’t know
88. No answer
99. Not asked
How often?	0. For less than yearly
1. Occasionally if unpredictably or less than monthly
2. Regularly (daily, weekly, monthly or predictably)
7. Don’t know
8. No answer
9. Not asked
'
# What I did: create a sum score of how often they attended any meetings -> This will not be ideal becasue it means that people who went to two types of meetings occasionally (perhaps only yearly) will have the same score as someone who went to one meeting regularly (multiple times a week) but alas it's an approximation
# Extract numbers after the colon and sum them (ignoring standalone numbers)
data_dwi$v96modified <- sapply(strsplit(data_dwi$v96, ", "), function(x) {
  # Keep only elements that contain ':'
  valid_entries <- x[grepl(":", x)]
  # Extract ALL numbers after ":" using gsub + regmatches + gregexpr
  extracted_numbers <- as.numeric(unlist(regmatches(valid_entries, gregexpr("(?<=:)[0-9]+", valid_entries, perl = TRUE))))
  # Sum up the extracted frequencies
  sum(extracted_numbers, na.rm = TRUE)
})

## Any of the following problems with eyes?
data_dwi$v328 # Print -> Only three participants with multiple answers and one .
'Has a doctor told you that you have any of the following problems with your eyes? (YOU CAN SELECT MORE THAN ONE ANSWER) 	1. Diabetes related eye disease 
2. Glaucoma 
3. Injury OR trauma resulting in loss of vision 
4. Cataract 
5. Macular degeneration 
6. Other serious eye condition 
0. None of the above 
7. Do not know 
8. No answer
9. Not asked	If 0 (None) goto IntroHC2/HC11
'
# What I did: 0 = No eye problem; 1-6 = 1 meaning yes, there is a problem; 7-9 = NA
v328_mapping <- c("0" = 0,
                  "1" = 1,
                  "2" = 1,
                  "3" = 1,
                  "4" = 1,
                  "5" = 1,
                  "6" = 1,
                  "7" = NA,
                  "8" = NA,
                  "9" = NA)

data_dwi$v328_modified <- v328_mapping[data_dwi$v328]
data_dwi$v328_modified <- as.numeric(data_dwi$v328_modified)

## Line read - Left eye 
data_dwi$v333 # Print -> Coded in letters, need to be transformed
'Left eye	A: Can’t read any line
B: 4.0
C: 2.0
D: 1.4
E: 1.2
F: 1.0
G: 0.8
H: 0.6
I: 0.5
J: 0.4
'
# I will map A as 0 and B as 2 and so on; So a higher score should be positively correlated with outcomes "higher vision retention is positively associated with outcomes"
# Ensure all letters are uppercase and remove spaces
data_dwi$v333modified <- trimws(toupper(data_dwi$v333))
# Define the reversed mapping (J=0, I=1, ..., A=9) # did not work
reversed_mapping <- setNames(9:0, rev(LETTERS[1:10]))  
# Convert column from letters to numbers, replacing unmatched values with NA
data_dwi$v333modified <- as.numeric(reversed_mapping[data_dwi$v333modified])
table(data_dwi$v334)

## Line read - Right eye
data_dwi$v334 # Print -> Coded in letters, need to be transformed
# I will map A as 0 and B as 2 and so on; So a higher score should be positively correlated with outcomes "higher vision retention is positively associated with outcomes"
# Ensure all letters are uppercase and remove spaces
data_dwi$v334modified <- trimws(toupper(data_dwi$v334))
# Define the reversed mapping (J=0, I=1, ..., A=9)
reversed_mapping <- setNames(9:0, rev(LETTERS[1:10]))  #did not work
# Convert column from letters to numbers, replacing unmatched values with NA
data_dwi$v334modified <- as.numeric(reversed_mapping[data_dwi$v334modified])


# Line read - Both eyes
data_dwi$v335 # Print -> Coded in letters, need to be transformed
# I will map A as 0 and B as 2 and so on; So a higher score should be positively correlated with outcomes "higher vision retention is positively associated with outcomes"
# Ensure all letters are uppercase and remove spaces
data_dwi$v335modified <- trimws(toupper(data_dwi$v335))
# Define the reversed mapping (J=0, I=1, ..., A=9)
reversed_mapping <- setNames(9:0, rev(LETTERS[1:10]))  #did not work
# Convert column from letters to numbers, replacing unmatched values with NA
data_dwi$v335modified <- as.numeric(reversed_mapping[data_dwi$v335modified])


# Smoking summary             
unique(data_dwi$smoker) # Print unique values-> Coded in words, needs to be transformed 
# rank the answers by severity 'Because it is cross sectional analysis, current smoker will be ranked as worse than non current'
# Worse smoking habit with lowest score so that better smoking habits are positively correlated with outcomes
### Should I distinguish between current and past smoker? rather than one scale
smoke_mapping <- c("N/A" = NA,
                   "NULL" = NA,
                   "NA" = NA,
                   "Current smoker" = 1,
                   "Past smoker" = 2,
                   "Occasional current, at least 100" = 3,
                   "Non current, at least 100" = 4,
                   "Occasional current, less than 100" = 5,
                   "Non current, less than 100" = 6,
                   "Never smoked" = 7
)
data_dwi$smokermodified <- smoke_mapping[data_dwi$smoker]
data_dwi$smokermodified <- as.numeric(data_dwi$smokermodified)


# alcohol summary             
unique(data_dwi$alcohol) # Print -> Coded in words, needs to be transformed
# rank the answers by severity 'Because it is cross sectional analysis, current smoker will be ranked as worse than non current'
# Worse smoking habit with lowest score so that better smoking habits are positively correlated with outcomes
## Should I distinguish between current and past drinker?
alcohol_mapping <- c("N/A" = NA,
                     "NA" = NA,
                     "Drinks daily" = 1,
                     "Drink three/four times weekly" = 2,
                     "Drinks once/twice weekly" = 3,
                     "Occasional drinker" = 4,
                     "Drinks one/three times monthly" = 5,
                     "Past drinker" = 6,
                     "Non drinker" = 7)

data_dwi$alcoholmodified <- alcohol_mapping[data_dwi$alcohol]
data_dwi$alcoholmodified <- as.numeric(data_dwi$alcoholmodified)


#HADS depression category
unique(data_dwi$HADS_dep_category)  # Print -> Coded in words, needs to be transformed
HADS_mapping <- c("Null" = NA,
                  "NA" = NA,
                  "Severe" = 1,
                  "Moderate" = 2,
                  "Mild" = 3,
                  "Normal" = 4)

data_dwi$HADSmodified <- HADS_mapping[data_dwi$HADS_dep_category]
data_dwi$HADSmodified <- as.numeric(data_dwi$HADSmodified)

#highest qualification
(data_dwi$qual) # Print -> Coded in words, needs to be transformed
qual_mapping <- c("NA" = NA,
                  "None" = 1,
                  "GCSE/O-level" = 2,
                  "A-level" = 3,
                  "Degree" = 4)

data_dwi$qualmodified <- qual_mapping[data_dwi$qual]
data_dwi$qualmodified <- as.numeric(data_dwi$qualmodified)
table(data_dwi$qualmodified)

##All the variables that are numeric but have NaN as string for NAs
#####
#Height    
data_dwi$height    # Print -> Technically in numbers, so further inspection
data_dwi$height[data_dwi$height == "NaN"] <- NA # So that NaN os no longer a string
data_dwi$height<- as.numeric(data_dwi$height)

#weight    
data_dwi$weight    # Print -> Technically in numbers, so further inspection
data_dwi$weight[data_dwi$weight == "NaN"] <- NA # So that NaN os no longer a string
data_dwi$weight <- as.numeric(data_dwi$weight)

#bp_sys2
data_dwi$bp_sys2
data_dwi$bp_sys2[data_dwi$bp_sys2 == "NaN"] <- NA # So that NaN os no longer a string
data_dwi$bp_sys2 <- as.numeric(data_dwi$bp_sys2)

#bp_sys3 
data_dwi$bp_sys3
data_dwi$bp_sys3[data_dwi$bp_sys3 == "NaN"] <- NA # So that NaN os no longer a string
data_dwi$bp_sys3 <- as.numeric(data_dwi$bp_sys3)

# Cattell 1          
data_dwi$C1.y     # Print -> Technically in numbers, so further inspection
data_dwi$C1.y[data_dwi$C1.y == "NaN"] <- NA # So that NaN os no longer a string
data_dwi$C1.y <- as.numeric(data_dwi$C1.y)

# Cattell 2
data_dwi$C2.y       # Print -> Technically in numbers, so further inspection
data_dwi$C2.y[data_dwi$C2.y == "NaN"] <- NA # So that NaN os no longer a string
data_dwi$C2.y <- as.numeric(data_dwi$C2.y)

#Cattell 3
data_dwi$C3.y       # Print -> Technically in numbers, so further inspection
data_dwi$C3.y[data_dwi$C3.y == "NaN"] <- NA # So that NaN os no longer a string
data_dwi$C3.y <- as.numeric(data_dwi$C3.y)

# Cattell 4
data_dwi$C4.y       # Print -> Technically in numbers, so further inspection
data_dwi$C4.y[data_dwi$C4.y == "NaN"] <- NA # So that NaN os no longer a string
data_dwi$C4.y <- as.numeric(data_dwi$C4.y)

# White Matter measures
data_dwi$WMHI_NORM_TIV     # Print -> Technically in numbers, so further inspection 
data_dwi$WMHI_NORM_TIV[data_dwi$WMHI_NORM_TIV == "NaN"] <- NA # So that NaN os no longer a string
data_dwi$WMHI_NORM_TIV <- as.numeric(data_dwi$WMHI_NORM_TIV)

data_dwi$FA_mean           # Print -> Technically in numbers, so further inspection
data_dwi$FA_mean[data_dwi$FA_mean == "NaN"] <- NA # So that NaN os no longer a string
data_dwi$FA_mean <- as.numeric(data_dwi$FA_mean)

data_dwi$MSD_mean          # Print -> Technically in numbers, so further inspection
data_dwi$MSD_mean[data_dwi$MSD_mean == "NaN"] <- NA # So that NaN os no longer a string
data_dwi$MSD_mean <- as.numeric(data_dwi$MSD_mean)

data_dwi$MSK_mean  # Print -> Technically in numbers, so further inspection
data_dwi$MSK_mean[data_dwi$MSK_mean == "NaN"] <- NA # So that NaN os no longer a string
data_dwi$MSK_mean <- as.numeric(data_dwi$MSK_mean)

data_dwi$NDI_mean  # Print -> Technically in numbers, so further inspection
data_dwi$NDI_mean[data_dwi$NDI_mean == "NaN"] <- NA # So that NaN os no longer a string
data_dwi$NDI_mean <- as.numeric(data_dwi$NDI_mean)

data_dwi$ODI_mean  # Print -> Technically in numbers, so further inspection
data_dwi$ODI_mean[data_dwi$ODI_mean == "NaN"] <- NA # So that NaN os no longer a string
data_dwi$ODI_mean <- as.numeric(data_dwi$ODI_mean)

data_dwi$Fiso_mean # Print -> Technically in numbers, so further inspection
data_dwi$Fiso_mean[data_dwi$Fiso_mean == "NaN"] <- NA # So that NaN os no longer a string
data_dwi$Fiso_mean <- as.numeric(data_dwi$Fiso_mean)

data_dwi$CCIDmodified <- sub("^CC", "", data_dwi$CCID)
data_dwi$CCIDmodified <- as.numeric(data_dwi$CCIDmodified)

######### SUBSET OF ONLY NUMERIC VARIABLES ##########
#####################################################

ncol(data_dwi) #188
sapply(data_dwi, class) # Returns the class of each column
# Only non-numeric columns
sapply(data_dwi, class)[sapply(data_dwi,class)=="character"]


## Exclude non numeric columns
num_data <- data_dwi[, sapply(data_dwi, is.numeric)]
ncol(num_data) #177 (because we excluded CCID,V14 and V73)

##Columns that were modified for future reference
grep("modified", names(num_data), value = TRUE)


################# COVARIANCE MATRIX ################
####################################################

cov_matrix <- cor(num_data, use = "pairwise.complete.obs")
corrplot(cov_matrix, method = "color", type = "upper", tl.col = "black", tl.cex = 0.7) #See if any patterns already visible (not really, lots of seemingly unrelated variables)


######## COMPUTATION OF NEW VARIABLES FOR CFA ###########
#########################################################

## BMI
num_data$BMI <- num_data$weight / ((num_data$height/100)^2) #weight in kg, height in cm
print(num_data$BMI)

## Blood Pressure
#systolic BP
num_data$bp_sys <- rowMeans(cbind(num_data$bp_sys2, num_data$bp_sys3), na.rm = TRUE) #Averaged because README file of Cardio says so

#Age since hypertension diagnosis
# How long hypertension has been diagnosed
table(num_data$v350)
# Recode so 9999 are NAs
num_data$v350m <- num_data$v350
num_data$v350m[num_data$v350 == 9999] <- NA
num_data$v350m[num_data$v350 == 790] <- NA
# compute duration of hypertension diagnosis so that it is Age - Age of diagnosis
num_data$v350proxy <- num_data$Age - num_data$v350m
table(num_data$v350proxy)


## Diabetes
# How long diabetes has been diagnosed
table(num_data$v378)
# Recode so 9999 are NAs
num_data$v378m <- num_data$v378
num_data$v378m[num_data$v378 == 9999] <- NA
# compute duration of diabetes diagnosis so that it is Age - Age of diagnosis
num_data$v378proxy <- num_data$Age - num_data$v378m
table(num_data$v378proxy)

## High Cholesterol
# How long cholesterol has been diagnosed
table(num_data$v356)
# Recode so 9999 are NAs
num_data$v356m <- num_data$v356
num_data$v356m[num_data$v356 == 9999] <- NA
# compute duration of cholesterol diagnosis so that it is Age - Age of diagnosis
num_data$v356proxy <- num_data$Age - num_data$v356m
table(num_data$v356proxy)


######## UNIFORM CODING FOR ALL VARIABLES FOR CFA ###########
#############################################################
'Description: Every variable is coded differently. Some NAs are 9 or 8 or 7 or somehing else. 
So, now I will go through all variables manually and code them so that they are uniformly coded.
I will start by listing which variables will be mapped to each factor befor re-coding them, if necessary 
The premise will be to have higher scores for healthier habits.
'

#### ALCOHOL
'Variabels: alcoholmodified, v290m, v291m, v293m, v294m, v295m, v296m, v297m
'

#alcoholmodified = scale of severity of drinking habit, larger numbers are more healthy habits, i.e. non drinkers
num_data$alcoholmodified

#v290 
num_data$v290
'About how often do you drink alcohol? 
1. Daily OR almost daily 
2. Three OR four times a week 
3. Once OR twice a week 
4. One to three times a month 
5. Special occasions only 
6. Never
7. Don’t know
8. No answer
9. Not asked
'
## Recode so that 7-9 are NA
v290_mapping <- c("1" = 1, "2" = 2, "3" = 3, "4" = 4, "5" = 5,
                  "6" = 6, "7" = NA, "8" = NA, "9" = NA)

num_data$v290m <- v290_mapping[num_data$v290]
num_data$v290m <- as.numeric(num_data$v290m)

#v291
num_data$v291
'
Did you previously drink alcohol? 
1. Yes 
2. No 
7. Don’t know
8. No answer
9. Not asked
'
## Recode so that 7-9 are NA
v291_mapping <- c("1" = 1, "2" = 2, "7" = NA, "8" = NA, "9" = NA)
num_data$v291m <- v291_mapping[as.character(num_data$v291)]
num_data$v291m <- as.numeric(num_data$v291m)

# v292 
unique(num_data$v292)
'Why did you stop drinking alcohol? 
1. Illness OR ill health 
2. Doctor’s advice 
3. Health precaution 
4. Financial reasons 
5. Other reason 
7. Do not know 
8. No answer 
9999. NA
'
## Exclude, does not directly indicate the intensity of drinking 

#v293
unique(num_data$v293)
'In an average week, how many glasses of red wine would you drink? 
Enter number OR 
66. Less than 1
77. Do not know
88. No answer 
99. Not asked
'
# Re-code, 66 = 0.5 because less than one, rest of given answers NA
v293_mapping <- c("66" = 0.5, "0" = 0, "1" = 1, "1.5" = 1.5, "2" = 2, "3" = 3, "4" = 4, 
                  "5" = 5, "6" = 6, "7" = 7, "8" = 8, "9" = 9, "10" = 10, "12" = 12, 
                  "14" = 14, "15" = 15, "18" = 18, "20" = 20, "24" = 24, "28" = 28, 
                  "30" = 30, "36" = 36, "42" = 42, "77" = NA, "88" = NA, "99" = NA)

num_data$v293minv <- v293_mapping[as.character(num_data$v293)]
num_data$v293minv <- as.numeric(num_data$v293minv)
num_data$v293m <- num_data$v293minv*-1
table(num_data$v293m)

#v294
unique(num_data$v294)
'In an average week, how many glasses of white wine or champagne would you drink?
66. Less than 1
77. Do not know
88. No answer 
99. Not asked
'
# Re-code, 66 = 0.5 because less than one, rest of given answers NA
v294_mapping <- c("66" = 0.5, "0" = 0, "1" = 1, "1.5" = 1.5, "2" = 2, "3" = 3, "4" = 4, 
                  "5" = 5, "6" = 6, "7" = 7, "8" = 8, "9" = 9, "10" = 10, "12" = 12, 
                  "14" = 14, "15" = 15, "18" = 18, "19" = 19, "20" = 20, "21" = 21, "28" = 28, 
                  "30" = 30, "77" = NA, "88" = NA, "99" = NA)

num_data$v294minv <- v294_mapping[as.character(num_data$v294)]
num_data$v294minv <- as.numeric(num_data$v294minv)
num_data$v294m <- num_data$v294minv*-1
table(num_data$v294m)

#v295 
unique(num_data$v295)
'In an average week how many pints of beer or cider would you drink? 
66. Less than 1
77. Do not know
88. No answer 
99. Not asked
'
# Re-code, 66 = 0.5 because less than one, rest of given answers NA
v295_mapping <- c("66" = 0.5, "0" = 0, "0.5" = 0.5, "1" = 1, "1.5" = 1.5, "2" = 2, "2.5" = 2.5, "3" = 3, "3.5" = 3.5, "4" = 4, 
                  "5" = 5, "6" = 6, "7" = 7, "8" = 8, "9" = 9, "10" = 10, "12" = 12, "13" = 13,
                  "14" = 14, "15" = 15, "16" = 16,  "20" = 20, "21" = 21, 
                  "100" = 100, "77" = NA, "88" = NA, "99" = NA)

num_data$v295minv <- v295_mapping[as.character(num_data$v295)]
num_data$v295minv <- as.numeric(num_data$v295minv)
num_data$v295m <- num_data$v295minv*-1
table(num_data$v295m)

# v296 
sort(unique(num_data$v296))
'In an average week how many standard measures of spirits or liqueurs would you drink? 
66. Less than 1
77. Do not know
88. No answer 
99. Not asked
'
# Re-code, 66 = 0.5 because less than one, rest of given answers NA
v296_mapping <- c("66" = 0.5, "0" = 0, "1" = 1,  "2" = 2,  "3" = 3, "4" = 4, 
                  "5" = 5, "6" = 6, "7" = 7, "8" = 8, "9" = 9, "10" = 10, "12" = 12, 
                  "14" = 14,  "21" = 21, "25" = 25, "662" = NA,
                  "77" = NA, "88" = NA, "99" = NA)

num_data$v296minv <- v296_mapping[as.character(num_data$v296)]
num_data$v296minv <- as.numeric(num_data$v296minv)
num_data$v296m <- num_data$v296minv*-1
table(num_data$v296m)

# v297
sort(unique(num_data$v297m))
'In an average week how many glasses of fortified wine would you drink? 
66. Less than 1
77. Do not know
88. No answer 
99. Not asked
'
# Re-code, 66 = 0.5 because less than one, rest of given answers NA
v297_mapping <- c("66" = 0.5, "0" = 0, "1" = 1,  "2" = 2,  "3" = 3, "4" = 4, 
                  "5" = 5, "6" = 6, "7" = 7, "8" = 8,
                  "14" = 14, 
                  "77" = NA, "88" = NA, "99" = NA)

num_data$v297minv <- v297_mapping[as.character(num_data$v297)]
num_data$v297minv <- as.numeric(num_data$v297minv)
num_data$v297m <- num_data$v297minv*-1
table(num_data$v297m)

# v298
'Compared to 10 years ago, do you drink? 	
1. More nowadays 
2. About the same 
3. Less nowadays 
7. Do not know 
8. No answer 
9. Not asked
'
## Exclude for now - no added knowlege of how much they are consuming

#### BMI - invert
# BMIm
table(num_data$BMIm)
num_data$BMIm <- num_data$BMI *-1

### DEPRESSION
'Variables: additional_HADS_depressionm, HADSmodified, v422m, v639m
'
#HADSmodified - DONE, see above
sort(unique(num_data$HADSmodified))

#HADS_depression
sort(unique(num_data$HADS_depression))
# Re-code, 9999 = NA
vHD_mapping <- c( "0" = 0, "1" = 1,  "2" = 2,  "3" = 3, "4" = 4, 
                  "5" = 5, "6" = 6, "7" = 7, "8" = 8, "9" = 9, "10" = 10, "11" = 11,
                  "12" = 12, "13" = 13, "15" = 15,"17" = 17, 
                  "9999" = NA)

num_data$HADS_depressionminv <- vHD_mapping[as.character(num_data$HADS_depression)]
num_data$HADS_depressionminv <- as.numeric(num_data$HADS_depressionminv)
num_data$HADS_depressionm <- num_data$HADS_depressionminv*-1
table(num_data$HADS_depressionm)

#v422
sort(unique(num_data$v422))
'Depression requiring treatment	
1. No 
2. Yes 
7. Don’t know
8. No answer
9. Not asked'

# Re-code, 9 = NA
v422_mapping <- c( "1" = 1,  "2" = 2,
                   "9" = NA)

num_data$v422minv <- v422_mapping[as.character(num_data$v422)]
num_data$v422minv <- as.numeric(num_data$v422minv)
num_data$v422m <- num_data$v422minv*-1
table(num_data$v422m)

#v639
sort(unique(num_data$v639m))
'Depression requiring treatment
1. No 
2. Yes 
7. Don’t know
8. No answer
9. Not asked
'
#Re-code so 7-9 = NA
v639_mapping <- c( "1" = 1,  "2" = 2,
                   "7"=NA,"8"=NA,"9" = NA)

num_data$v639minv <- v639_mapping[as.character(num_data$v639)]
num_data$v639minv <- as.numeric(num_data$v639minv)
num_data$v639m <- num_data$v639minv*-1
table(num_data$v639m)

#v640
sort(unique(num_data$v640))
'Age'
# Exclude for now - No direct indication of severity of depression


# DIABETES
'variables: v377, v378 (excluded, cause just age), v378proxym'
num_data$v377
'Diabetes (not during pregnancy)	
1. No 
2. Yes 
7. Don’t know
8. No answer
9. Not asked
'
v377_mapping <- c( "1" = 1,  "2" = 2,
                   "7"=NA,"8"=NA,"9" = NA)

num_data$v377minv <- v377_mapping[as.character(num_data$v377)]
num_data$v377minv <- as.numeric(num_data$v377minv)
num_data$v377m <- num_data$v377minv*-1
table(num_data$v377m)

#v378proxy # invert
num_data$v378proxym <- num_data$v378proxy *-1

# EDUCATION
'variables: qualmodified, v74, yearsedum'


table(num_data$v74) #To be discussed, exclude for now (we could either subtract from current age
# to have a measuer of how many years ago its been, given there is evidence, that if it is too long ago
# it does not have en effect, or we use it as is but reverse coding)

#question_num_years_edu
num_data$yearsedu <- num_data$question_num_years_edu
num_data$yearsedum <- num_data$yearsedu

# HEARING LOSS
'variables: v336m, v337m, v338m, v339m, v344m, v345m, v346m, v347m, v620m
'

#v336
unique(num_data$v336)
'Do you have any difficulty with your hearing? 	
1. No 
2. Yes 
7. Don’t know
8. No answer
9. Not asked'
#v337
'Do these problems interfere with your day to day living	
1. No 
2. Yes 
7. Don’t know
8. No answer
9. Not asked'
#v338
'Do you find it difficult to follow a conversation if there is background noise (such as TV, radio, children playing)? 	
1. No 
2. Yes 
7. Don’t know
8. No answer
9. Not asked'
#v339
'Do you use a hearing aid most of the time? 
1. No 
2. Yes 
7. Don’t know
8. No answer
9. Not asked'

# get rid of duplicate columns ot perform mutate()
names(num_data)[duplicated(names(num_data))]
names(num_data) <- make.names(names(num_data), unique = TRUE)

### UNIFROM CODING, so that 7/8/9 are NA

v336789_mapping <- c( "1" = 2,  "2" = 1,
                      "7"=NA,"8"=NA,"9" = NA)

num_data <- num_data %>%
  mutate(across(
    all_of(c("v336", "v337", "v338", "v339")),
    ~ as.numeric(v336789_mapping[as.character(.)]),
    .names = "{.col}m"  # creates v336m, v337m, etc.
  ))

## print to double check
cols <- c("v336m", "v337m", "v338m", "v339m")

for (col in cols) {
  cat("\nUnique values in", col, ":\n")
  print(unique(num_data[[col]]))
}
#v340
'Can it be removed?' #Exclude, difficult to interpret

#v342
'Wearing a Hearing Aid' # exclude for now, difficult to interpret, could not be wearing one but still have issues, if included this should be conditional on whether they have issues

#v344
table(num_data$v344m) 
'Number of tones heard 1-3'
v344_mapping <- c( "1" = 1,  "2" = 2,
                   "3"=3,"7"=NA, "8"=NA,"9"=NA)

num_data$v344m <- v344_mapping[as.character(num_data$v344)]
num_data$v344m <- as.numeric(num_data$v344m)

#v345
table(num_data$v345m) # same mapping as v344
num_data$v345m <- v344_mapping[as.character(num_data$v345)]
num_data$v345m <- as.numeric(num_data$v345m)

#v346
table(num_data$v346m) # isame mapping as v344
num_data$v346m <- v344_mapping[as.character(num_data$v346)]
num_data$v346m <- as.numeric(num_data$v346m)

#v347
table(num_data$v347m) #  same mapping as v344
num_data$v347m <- v344_mapping[as.character(num_data$v347)]
num_data$v347m <- as.numeric(num_data$v347m)

#v620
'Hearing problems that interfered with questioning	
1. No
2. To some extent
3. To marked extent
4. Deaf'
table(num_data$v620) 
num_data$v620m <- num_data$v620*-1
table(num_data$v620m)# okay as is

# High Blood Pressure
'variable: v349m, v352m, v354m, v629m, v632m, v634m, bp_sys, v350proxym
'

#v350proxy # invert
num_data$v350proxym <- num_data$v350proxy *-1

#v349
'High blood pressure (hypertension) 
1. No 
2. Yes 
7. Don’t know
8. No answer
9. Not asked'

#354
'Is your HBP still uncontrolled?	
1. No 
2. Yes 
7. Don’t know
8. No answer
9. Not asked'
# 629
'High blood pressure (hypertension) (hypertension during pregnancy does not count here)	
1. No 
2. Yes 
7. Don’t know
8. No answer
9. Not asked'

#634
'Is your HBP still uncontrolled?	
1. No 
2. Yes 
7. Don’t know
8. No answer
9. Not asked'

### UNIFORM CODING, so that 7/8/9 are NA, and invert 1/2

### BLOOD PRESSURE
BP_mapping <- c( "1" = 2,  "2" = 1,
                 "7"=NA,"8"=NA,"9" = NA)

num_data <- num_data %>%
  mutate(across(
    all_of(c("v349", "v354", "v629", "v634")),
    ~ as.numeric(BP_mapping[as.character(.)]),
    .names = "{.col}m"  # creates v354m, v349m, etc.
  ))

## print to double check
cols <- c("v349m", "v354m", "v629m", "v634m")

for (col in cols) {
  cat("\nUnique values in", col, ":\n")
  print(unique(num_data[[col]]))
}


#632
'Did/do you receive medication for your High blood pressure (hypertension))	
1. No 
2. Yes 
7. Don’t know
8. No answer
9. Not asked'
#352
'Did/do you receive medication for your High blood pressure (hypertension))
1. No 
2. Yes 
7. Don’t know
8. No answer
9. Not asked'
## Recode NAs
BP2_mapping <- c( "1" = 1,  "2" = 2,
                  "7"=NA, "8"=NA,"9"=NA)
#v352m
num_data$v352m <- BP2_mapping[as.character(num_data$v352)]
num_data$v352m <- as.numeric(num_data$v352m)
#v632
num_data$v632m <- BP2_mapping[as.character(num_data$v632)]
num_data$v632m <- as.numeric(num_data$v632m)

#bp_sys
'Measured on day of scanning by RA, twice. This is the average of systolic blood pressure'
# invert
num_data$bp_sys <- num_data$bp_sys *-1

### HIGH CHOLESTEROL
'variables: v355m, v356proxym
'
#v355 # invert and NAs
'High blood cholesterol (hyperlipidaemia)	
1. No 
2. Yes 
7. Don’t know
8. No answer
9. Not asked
'
v355_mapping <- c( "1" = 2,  "2" = 1,
                   "7"=NA, "8"=NA,"9"=NA)

num_data$v355m <- v355_mapping[as.character(num_data$v355)]
num_data$v355m <- as.numeric(num_data$v355m)

#v356proxy # invert
num_data$v356proxym <- num_data$v356proxy *-1

### PHYSICAL ACTIVITY 
'Variables: activities_done, ACTMETS, CARadj, CARMILES, COMMUTE_METS, COMMUTE_PAEE, 
COMMUTEtime, CYCLEadj, CYCLEMILES, DURGETABOUT_BIKE, DURGETABOUT_WALK, DURJOB, DURTV, 
GETABOUT, GETABOUT_bikedist, GETABOUT_walkdist, GETABOUTBIKadj, GETABOUTWALKadj, HOME_METS, 
HOME_PAEE, HOMEtime, LEIS_METS, LEIS_PAEE, LEIStime, leisure_missing_all_data, 
leisure_missing_duration, leisure_missing_freq, LIGHT_INTENSITY, LIGHTtime, MODERATE_INTENSITY,
MODERATEtime, PAEE, PUBLICadj, PUBLICMILES, SED_INTENSITY, SEDtime, SLEEPtime, TOTALtime, 
TOTMETHRS, TOTMETHRS_w_UNACCtime, TVadj, UNACCOUNTED_TIME, VIGOROUS_INTENSITY, VIGOROUStime, 
WALKadj, WALKMILES, WORK_METS, WORK_PAEE, WORKtime'
'Potential new variables:
PAEE - physical activity energy expenditure (aggregate measure of energy burned'
#source: https://www.epic-norfolk.org.uk/2019/07/27/keeping-active-or-becoming-more-active-in-middle-and-older-age-linked-to-longer-life/
#HOME_PAEE # higher value = more burned/ healthier
num_data$HOME_PAEE
#LEIS_PAEE
num_data$LEIS_PAEE
#PAEE
num_data$PAEE
#WORK_PAEE
num_data$WORK_PAEE
#Test
num_data$LEIS_PAEE + num_data$HOME_PAEE + num_data$WORK_PAEE == num_data$PAEE # sometimes true, trying to understand whether PAEE is a composite score of all three PAEEs
'can stay the way it is with higher scores, indicating healthier lifestyle'


### SMOKING
'variables: smokermodified, v241m, v242m, v244m, v245m, v247m, v251m, v252m, v253m, v255m, v256m, v259m, v260m, v261m
'
#smokermodified
table(num_data$smokermodified) # here: higher number, HEALTHIER Habit, need to recode the rest accordingly!!!
#v241 # recode so 7/8/9 are NAs
'Do you smoke tobacco now? 
1. Yes, on most or all days 
2. Only occasionally 
3. No 
7. Don’t know
8. No answer 
9. Not asked
'
v241_mapping <- c( "1" = 1,  "2" = 2,
                   "3"=3,"7"=NA, "8"=NA,"9"=NA)

num_data$v241m <- v241_mapping[as.character(num_data$v241)]
num_data$v241m <- as.numeric(num_data$v241m)

#v242 #NA coding + rest okay, because older = "healthier" so higher number is healthier, which is ok
'How old were you when you first started smoking on most days?
Enter number OR 
777. Don’t know
888. No answer
999. Not asked'
num_data$v242m <- num_data$v242
num_data$v242m[num_data$v242 == 777] <- NA
num_data$v242m[num_data$v242 == 888] <- NA
num_data$v242m[num_data$v242 == 999] <- NA
table(num_data$v242m)

#244 # recode for NAs
'Did you previously smoke cigarettes on most or all days? 
1. Yes 
2. No 
7. Don’t know
8. No answer 
9. Not asked
'
num_data$v244m <- num_data$v244
num_data$v244m[num_data$v244 == 7] <- NA
num_data$v244m[num_data$v244 == 8] <- NA
num_data$v244m[num_data$v244 == 9] <- NA
table(num_data$v244m)

#v245 # recode NAs + invert because here higher number means unhealthier habit
'About how many cigarettes did you smoke on average each day?
Enter number OR 
66. Less than one a day OR
77. Don’t know
88. No answer
99. Not asked 
'
num_data$v245m <- num_data$v245 * -1
num_data$v245m[num_data$v245 == 66] <- 0.5
num_data$v245m[num_data$v245 == 77] <- NA
num_data$v245m[num_data$v245 == 88] <- NA
num_data$v245m[num_data$v245 == 99] <- NA # does not always work, double check

table(num_data$v245m)

#v246
'How old were you when you last smoked cigarettes on most days? 	Enter number OR 
777. Don’t know
888. No answer
999. Not asked'
## Exclude for now, would really only make sense, if calculated as how long ago in comparison to now

#247 # recode NAs + invert because here higher number means unhealthier habit
'About how many cigarettes do you smoke on average each day? (include hand-rolled cigarettes if smoked) 	Enter number OR 
66. Less than one a day OR
77. Don’t know
88. No answer
99. Not asked
'
num_data$v247m <- num_data$v247 * -1
num_data$v247m[num_data$v247 == 66] <- 0.5
num_data$v247m[num_data$v247 == 77] <- NA
num_data$v247m[num_data$v247 == 88] <- NA
num_data$v247m[num_data$v247 == 99] <- NA # does not always work, double check
table(num_data$v247m)

#v249
'Compared to 10 years ago do you smoke? 	
1. More nowadays 
2. About the same 
3. Less nowadays 
7. Don’t know
8. No answer 
9. Not asked'
## Exclude for now, only gives us insight in relation to how long they smoked before

## Here below is NON-CURRENT smoker
#v251 # recode NAs
'In the past, how often have you smoked tobacco? 	
1. Smoked on most or all days 
2. Smoked occasionally 
3. Just tried once or twice 
4. I have never smoked 
7. Don’t know
8. No answer 
9. Not asked'
num_data$v251m <- num_data$v251 
num_data$v251m[num_data$v251 == 7] <- NA
num_data$v251m[num_data$v251 == 8] <- NA
num_data$v251m[num_data$v251 == 9] <- NA # does not always work, double check
table(num_data$v251m)

#v252 # recoded NAs
'In your lifetime, have you smoked a total of at least 100 times? 	
1. Yes 
2. No 
7. Don’t know
8. No answer
9. Not asked
'
num_data$v252m <- num_data$v252 
num_data$v252m[num_data$v252 == 7] <- NA
num_data$v252m[num_data$v252 == 8] <- NA
num_data$v252m[num_data$v252 == 9] <- NA # does not always work, double check
table(num_data$v252m)

#v253
'How old were you when you first started smoking on most days? 	
Enter age OR 
777. Do not know
888. No answer
999. Not asked 
'
num_data$v253m <- num_data$v253
num_data$v253m[num_data$v253 == 777] <- NA
num_data$v253m[num_data$v253 == 888] <- NA
num_data$v253m[num_data$v253 == 999] <- NA
num_data$v253m[num_data$v253 == 9999] <- NA
table(num_data$v253m)

#v255 # NAs
'Did you previously smoke cigarettes on most or all days? 	
1. Yes 
2. No 
7. Don’t know
8. No answer
9. Not asked
'
num_data$v255m <- num_data$v255 
num_data$v255m[num_data$v255 == 7] <- NA
num_data$v255m[num_data$v255 == 8] <- NA
num_data$v255m[num_data$v255 == 9] <- NA 
table(num_data$v255m)

#v256 # NAs and invert
'About how many cigarettes did you smoke on average each day? (include hand-rolled cigarettes if smoked) 	
Enter number OR 
66. Less than one a day OR
77. Don’t know
88. No answer
99. Not asked
'
num_data$v256m <- num_data$v256 * -1
num_data$v256m[num_data$v256 == 77] <- NA
num_data$v256m[num_data$v256 == 88] <- NA
num_data$v256m[num_data$v256 == 99] <- NA 
num_data$v256m[num_data$v256 == 66] <- 0.5 
table(num_data$v256m)

#v257
'How old were you when you last smoked cigarettes on most days? 	
Enter number OR 
777.Do not know
888. No answer
999. Not asked 
'
## Exclude for now, would really only make sense, if calculated as how long ago in comparison to now

#v259 # NAs + inverted
'Does anyone in your household smoke? 	
1. No 
2. Yes, one household member smokes 
3. Yes, more than one household member smokes 
7. Do not know 
8. No answer 
9. Not asked
'
num_data$v259m <- num_data$v259 * -1
num_data$v259m[num_data$v259 == 7] <- NA
num_data$v259m[num_data$v259 == 8] <- NA
num_data$v259m[num_data$v259 == 9] <- NA 
table(num_data$v259m)

#v260 # NAs + inverted
'At home, about how many hours per week are you exposed to other people’s tobacco smoke? 	
Enter number OR 
777. Do not know
888. No answer
999. Not asked
'
num_data$v260m <- num_data$v260 * -1
num_data$v260m[num_data$v260 == 777] <- NA
num_data$v260m[num_data$v260 == 888] <- NA
num_data$v260m[num_data$v260 == 999] <- NA 
table(num_data$v260m)

#v261 #Nas + inverted
'Outside of your home, about how many hours per week are you exposed to other people’s tobacco smoke? 	
Enter number OR 
777. Do not know
888. No answer
999. Not asked
'
num_data$v261m <- num_data$v261 * -1
num_data$v261m[num_data$v261 == 777] <- NA
num_data$v261m[num_data$v261 == 888] <- NA
num_data$v261m[num_data$v261 == 999] <- NA 
table(num_data$v261m)

### SOCIAL ISOLATION
'Variables: v5m, v86, v87m, v89, v90m, v91m,v92m,v93m,v94m, v95m, v96modified, v97m, v98m
'

#v14 # Excluded above
'How are the other people who live with you related to you? (YOU CAN SELECT MORE THAN ONE ANSWER) 	
0. Not related
1. Husband, wife or partner 
2. Son and/or daughter (include step children) 
3. Brother and/or sister 
4. Mother and/or father 
5. Grandchild 
6. Other related 
7. Do not know
8. No answer 
'

table(data_dwi$v14)
#v5
'What is your marital status?	
1. Single (never married)
2. Married / civil partnership
3. Co-habiting
4. Divorced/ separated
5. Widowed
'
table(num_data$v5)
# Recode, so higher = healthier (Tbd whether divorced is better than widowed)
num_data$v5m[num_data$v5 == 1] <- 1
num_data$v5m[num_data$v5 == 2] <- 5
num_data$v5m[num_data$v5 == 3] <- 4 
num_data$v5m[num_data$v5 == 4] <- 3
num_data$v5m[num_data$v5 == 5] <- 2 
table(num_data$v5m)


#v86 # okay
'Do you have any children of your own?	
1. No
2. Yes (include adopted children)
'

#v87
'How many	Enter number of living children'
table(num_data$v87) # 9999 = NA, rest is okay
num_data$v87m <- num_data$v87 
num_data$v87m[num_data$v87 == 9999] <- NA 
table(num_data$v87m)

#v89 # okay
'Do any of your close relatives live in the area or within easy reach of the area	1. No relatives
2. No relatives in area
3. Yes
'
table(num_data$v89)

#v90 # recode NAs and reorder
'How often do you see any of your relatives to speak to?	1. Never
2. Daily
3. 2-3 times a week
4. At least weekly
5. At least monthly
6. Less often
7. Don’t know
8. No answer
9. Not asked
'
table(num_data$v90)
num_data$v90m <- num_data$v90 
num_data$v90m[num_data$v90 == 1] <- 1 
num_data$v90m[num_data$v90 == 2] <- 6
num_data$v90m[num_data$v90 == 3] <- 5 
num_data$v90m[num_data$v90 == 4] <- 4 
num_data$v90m[num_data$v90 == 5] <- 3 
num_data$v90m[num_data$v90 == 6] <- 2 
num_data$v90m[num_data$v90 == 7] <- NA 
num_data$v90m[num_data$v90 == 8] <- NA 
num_data$v90m[num_data$v90 == 9] <- NA 
table(num_data$v90m)


#v91 # recode
'How often do you speak to your relatives over the phone?	1. Never
2. Daily
3. 2-3 times a week
4. At least weekly
5. At least monthly
6. Less often
7. Don’t know
8. No answer
9. Not asked
'
table(num_data$v91)
num_data$v91m <- num_data$v91 
num_data$v91m[num_data$v91 == 1] <- 1 
num_data$v91m[num_data$v91 == 2] <- 6
num_data$v91m[num_data$v91 == 3] <- 5 
num_data$v91m[num_data$v91 == 4] <- 4 
num_data$v91m[num_data$v91 == 5] <- 3 
num_data$v91m[num_data$v91 == 6] <- 2 
num_data$v91m[num_data$v91 == 7] <- NA 
num_data$v91m[num_data$v91 == 8] <- NA 
num_data$v91m[num_data$v91 == 9] <- NA 
table(num_data$v91m)

#v92
'How often do you text/email your relatives?	1. Never
2. Daily
3. 2-3 times a week
4. At least weekly
5. At least monthly
6. Less often
7. Don’t know
8. No answer
9. Not asked
'
table(num_data$v92)
num_data$v92m <- num_data$v92
num_data$v92m[num_data$v92 == 1] <- 1 
num_data$v92m[num_data$v92 == 2] <- 6
num_data$v92m[num_data$v92 == 3] <- 5 
num_data$v92m[num_data$v92 == 4] <- 4 
num_data$v92m[num_data$v92 == 5] <- 3 
num_data$v92m[num_data$v92 == 6] <- 2 
num_data$v92m[num_data$v92 == 7] <- NA 
num_data$v92m[num_data$v92 == 8] <- NA 
num_data$v92m[num_data$v92 == 9] <- NA 
table(num_data$v92m)

#v93
'How often do you visit friends or family or they visit you? 	01. Almost daily 
02. 2-4 times a week 
03. About once a week
04. About once a month
05. Once every few months 
06. Never or almost never 
07. No friends/family outside household 
77. Do not know
88. No answer 
'
table(num_data$v93)
num_data$v93m <- num_data$v93
num_data$v93m[num_data$v93 == 1] <- 6
num_data$v93m[num_data$v93 == 2] <- 5
num_data$v93m[num_data$v93 == 3] <- 4 
num_data$v93m[num_data$v93 == 4] <- 3 
num_data$v93m[num_data$v93 == 5] <- 2 
num_data$v93m[num_data$v93 == 6] <- 1 
num_data$v93m[num_data$v93 == 7] <- 7 #discuss whether highest, but it should mean that they live with them, so they see them the most, on the other hand it means small social circle 
num_data$v93m[num_data$v93 ==77] <- NA 
num_data$v93m[num_data$v93 ==88] <- NA 
table(num_data$v93m)

#v94
'How often do you speak to your friends over the phone?	1. Never
2. Daily
3. 2-3 times a week
4. At least weekly
5. At least monthly
6. Less often
7. Don’t know
8. No answer
9. Not asked
'
table(num_data$v94)
num_data$v94m <- num_data$v94
num_data$v94m[num_data$v94 == 1] <- 1 
num_data$v94m[num_data$v94 == 2] <- 6
num_data$v94m[num_data$v94 == 3] <- 5 
num_data$v94m[num_data$v94 == 4] <- 4 
num_data$v94m[num_data$v94 == 5] <- 3 
num_data$v94m[num_data$v94 == 6] <- 2 
num_data$v94m[num_data$v94 == 7] <- NA 
num_data$v94m[num_data$v94 == 8] <- NA 
num_data$v94m[num_data$v94 == 9] <- NA 
table(num_data$v94m)

#v95
'How often do you text/email your friends?	1. Never
2. Daily
3. 2-3 times a week
4. At least weekly
5. At least monthly
6. Less often
7. Don’t know
8. No answer
9. Not asked
'
table(num_data$v95)
num_data$v95m <- num_data$v95
num_data$v95m[num_data$v95 == 1] <- 1 
num_data$v95m[num_data$v95 == 2] <- 6
num_data$v95m[num_data$v95 == 3] <- 5 
num_data$v95m[num_data$v95 == 4] <- 4 
num_data$v95m[num_data$v95 == 5] <- 3 
num_data$v95m[num_data$v95 == 6] <- 2 
num_data$v95m[num_data$v95 == 7] <- NA 
num_data$v95m[num_data$v95 == 8] <- NA 
num_data$v95m[num_data$v95 == 9] <- NA 
table(num_data$v95m)
#v96modified
'Number of meetings attended per week'
#okay
#v97
'Do you have friends in this community?	1. No
2. Yes
7. Don’t know
8. No answer
9. Not asked
'
table(num_data$v97)
num_data$v97m <- num_data$v97
num_data$v97m[num_data$v97 == 7] <- NA 
num_data$v97m[num_data$v97 == 8] <- NA 
num_data$v97m[num_data$v97 == 9] <- NA 
table(num_data$v97m)
#v98
'How often do you see any of your neighbours to have a chat or do something with?	
0. No neighbours
1. Never
2. Daily
3. 2-3 times a week
4. At least weekly
5. At least monthly
6. Less often
7. Don’t know
8. No answer
9. Not asked'

table(num_data$v98)
num_data$v98m <- num_data$v98
num_data$v98m[num_data$v98 == 1] <- 1 
num_data$v98m[num_data$v98 == 2] <- 6
num_data$v98m[num_data$v98 == 3] <- 5 
num_data$v98m[num_data$v98 == 4] <- 4 
num_data$v98m[num_data$v98 == 5] <- 3 
num_data$v98m[num_data$v98 == 6] <- 2
num_data$v98m[num_data$v98 == 0] <- 0 
num_data$v98m[num_data$v98 == 7] <- NA 
num_data$v98m[num_data$v98 == 8] <- NA 
num_data$v98m[num_data$v98 == 9] <- NA 
table(num_data$v98m)

### TBI 
'variables: v457m, v459m, v542m, v543m, v545m'
#v457
'Have you ever had a serious head injury and been unconscious after it? (Have you ever been knocked out?)	1. No 
2. Yes 
7. Don’t know
8. No answer
9. Not asked
'
num_data$v457m <- num_data$v457
num_data$v457m[num_data$v457 == 1] <- 2 
num_data$v457m[num_data$v457 == 2] <- 1
num_data$v457m[num_data$v457 == 7] <- NA 
num_data$v457m[num_data$v457 == 8] <- NA 
num_data$v457m[num_data$v457 == 9] <- NA 
table(num_data$v457m)

#v459 # invert and NA
'Number of times	Numerical answer'
table(num_data$v459)
num_data$v459m <- num_data$v459 *-1
num_data$v459m[num_data$v459 == 9999] <- NA 
table(num_data$v459m)

#v460 # only 1 and NA for answers, so exclude, because no variation
'Did you lose consciousness for more than 2 hours?	1. No
2. Yes
'
table(num_data$v460)

#v542
'Have you fallen in the last year? (By falling I mean unintentionally coming to the floor, or ground or lower level such as landing on a chair or stair.)	
1. No
2. Yes
7. Don’t know
8. No answer
9. Not asked
'
num_data$v542m <- num_data$v542
num_data$v542m[num_data$v542 == 1] <- 2 
num_data$v542m[num_data$v542 == 2] <- 1
num_data$v542m[num_data$v542 == 7] <- NA 
num_data$v542m[num_data$v542 == 8] <- NA 
num_data$v542m[num_data$v542 == 9] <- NA 
table(num_data$v542m)

#v543
'Have you ever fallen?	1. No
2. Yes
7. Don’t know
8. No answer
9. Not asked
'
num_data$v543m <- num_data$v543
num_data$v543m[num_data$v543 == 1] <- 2 
num_data$v543m[num_data$v543 == 2] <- 1
num_data$v543m[num_data$v543 == 7] <- NA 
num_data$v543m[num_data$v543 == 8] <- NA 
num_data$v543m[num_data$v543 == 9] <- NA 
table(num_data$v543m)

#v544 #Exclude, unclear how to interpret, if better or worse that they fell long ago
'If you have ever fallen, when was the last time you fell?
  MM
77 Don’t know
88 No answer
99 Not asked '

#v545
'How many times	Numeric entry
77 Don’t know
88 No answer
99 Not asked'
num_data$v545m <- num_data$v545 * -1
num_data$v545m[num_data$v545 == 77] <- NA 
num_data$v545m[num_data$v545 == 88] <- NA 
num_data$v545m[num_data$v545 == 9999] <- NA 
table(num_data$v545m)

### VISION LOSS
'variables: v328m, v329m, v330m, v333modified, v334modified, v335modified, v621m
'
# v 328, 333, 334, 335 are modified
#v326 # exclude, only interpretable if person has vision imparment in the first place
'Do you wear glasses or contact lenses to correct your vision? 	1. No 
2. Yes 
7. Don’t know
8. No answer
9. Not asked
'
table(num_data$v326)

#v327 #Exclude hard to interpet, unless we know when vision impaiment set on
'What age did you first start to wear glasses or contact lenses? 	Enter number OR 
77. Do not know 
88. No answer
99. Not asked
'
#v328m
# What I did: 0 = No eye problem; 1-6 = 1 meaning yes, there is a problem; 7-9 = NA
table(num_data$v328_modified)
num_data$v328m <- num_data$v328_modified 
num_data$v328m[num_data$v328_modified == 0] <- 2 
num_data$v328m[num_data$v328_modified == 1] <- 1 
table(num_data$v328m)

#v329
'Do you have any other problems with your eyes or eyesight? 	1. No 
2. Yes 
7. Don’t know
8. No answer
9. Not asked'

num_data$v329m <- num_data$v329
num_data$v329m[num_data$v329 == 1] <- 2 
num_data$v329m[num_data$v329 == 2] <- 1
num_data$v329m[num_data$v329 == 7] <- NA 
num_data$v329m[num_data$v329 == 8] <- NA 
num_data$v329m[num_data$v329 == 9] <- NA 
table(num_data$v329m)

#v330
'Do any of these eye problems interfere with day to day living	1. No 
2. Yes 
7. Don’t know
8. No answer
9. Not asked
'
num_data$v330m <- num_data$v330
num_data$v330m[num_data$v330 == 1] <- 2 
num_data$v330m[num_data$v330 == 2] <- 1
num_data$v330m[num_data$v330 == 7] <- NA 
num_data$v330m[num_data$v330 == 8] <- NA 
num_data$v330m[num_data$v330 == 9] <- NA 
table(num_data$v330m)

#v331 # Exclude, consent
'Are you happy for me to do this?	1. Yes
2. No, blind in both eyes
3. No, some vision loss doesn’t want to
4. No, can’t read (volunteered)
5. No, other reason
'
#v332
'RESPONDENT USING GLASSES/CONTACT LENSES	1. Yes
2. No'
#  exclude, only helpful ig we know if there is vision impariment

#v333modified # okay
#v334modified # okay
#v335modified # okay

#v621 # invert
'Poor/no eyesight that interfered with reading, writing or drawing	1. No
2. To some extent
3. To marked extent
4. Blind
'
table(num_data$v621)
num_data$v621m <- num_data$v621 *-1
table(num_data$v621m)

#v668 # Exclude, Hard to interpret
'Have you ever had an operation on your eyes?	1. No
2. Yes
'
#v669 # Exclude Hard to interpret
'What kind? (IF MORE THAN ONE INCLUDES OTHER OPERATION THEN CODE THAT) 	1. Cataract surgery
2. Laser treatment
3. Corneal grafts
4. Other operations (including eye prosthesis)
'

### AIR POLLUTION
'currently not included'

###################################################################### CONFIRMATORY FACTOR ANALYSIS ############################################################
################################################################################################################################################################

################# NEW DATAFRAME WITH RECODED VARIABLES ##############
#####################################################################

#Dataframe for model 82 variables
df_cfa <- num_data %>%
  select( CCIDmodified, Age, alcoholmodified ,v290m,v291m, v293m, v294m, v295m, v296m, v297m,
          BMIm,
          HADS_depressionm, HADSmodified, v422m, v639m,
          v377m , v378proxym,
          qualmodified , yearsedum,
          v336m, v337m, v338m, v339m, v344m, v345m, v346m, v347m, v620m,
          v349m, v352m, v354m, v629m, v632m, v634m , bp_sys , v350proxym,
          v355m , v356proxym,
          HOME_PAEE, LEIS_PAEE, COMMUTE_PAEE, WORK_PAEE,PAEE,
          smokermodified, v241m, v242m, v244m, v245m, v247m, v251m, v252m, v253m, v255m, v256m, v259m, v260m, v261m,
          v5m, v86, v87m, v89, v90m, v91m,v92m,v93m,v94m, v95m, v96modified, v97m, v98m,
          v457m, v459m, v542m, v543m, v545m,
          v328m, v329m, v330m, v333modified, v334modified, v335modified, v621m,
  )



###################### STEPWISE DATA CLEANING ####################
##################################################################

# Check for NAs, percentage
na_percent <- round(colMeans(is.na(df_cfa)) *100, 2)
na_percent
## over 25% NAs
high_na_cols <- names(na_percent[na_percent > 25])
high_na_cols

## Exclude all the variables with more than 25% NAs
df_clean <- df_cfa[ , colMeans(is.na(df_cfa)) <= 0.25] #excluded 30 variables

#Check if any column has 0 variance
which(sapply(df_clean, function(x) var(x, na.rm = TRUE) == 0)) #0

## Check if any participants have more than 25% NAs
nrow(df_clean) #708
row_na_prop <- rowMeans(is.na(df_clean))
df_cleanp <- df_clean[row_na_prop <= 0.25, ]
setdiff(df_clean$CCID, df_cleanp$CCID)
nrow(df_cleanp) #706, two participants were kicked out

## Scale data
my_data_scaled <- scale(df_cleanp) # because some variables are by factor 1000 larger


########## Model without clean variables/participants >25% NAs ########
#######################################################################

#Adjusted model #  without variables >25% NAs 
CFA_Model <- 
  'Alcohol =~ alcoholmodified + v290m
  BMIf =~ BMIm
  Depression =~ HADS_depressionm+ HADSmodified+ v422m
  Diabetes =~ v377m
  Education =~ qualmodified + yearsedum
  Hearing =~ v336m+ v338m+ v339m+ v344m+ v345m+ v346m+ v347m+ v620m
  BP =~ v349m+ bp_sys
  Cholesterol =~ v355m 
  PhysicalActivity =~ PAEE + HOME_PAEE + LEIS_PAEE + COMMUTE_PAEE + WORK_PAEE
  Smoking =~ smokermodified+ v241m+  v251m+ v259m+ v261m
  SocialIsolation =~ v5m+ v86+ v89+ v90m+ v91m+v92m+v93m+v94m+ v95m+ v96modified+ v97m+ v98m
  TBI =~ v457m+ v542m+ v543m
  Vision =~ v328m+ v333modified+ v334modified+ v335modified+ v621m'


#investigate which variables have low convergence
## check covariance
fit <- cfa(CFA_Model, data = my_data_scaled, missing = "fiml", em.h1.iter.max = 10000, verbose = TRUE, do.fit = FALSE, optim.method = "BFGS") # Error, and warnign that variance-covariance matrix is not good
lavInspect(fit, "converged") #False 
lavInspect(fit, "coverage") 

## Check how complex the model is
length(all.vars(parse(text = CFA_Model))) #63

### Delete which variables have low coverage
# Extract the coverage matrix
coverage_matrix <- lavInspect(fit, "coverage")

# Calculate mean pairwise coverage for each variable
coverage_means <- rowMeans(coverage_matrix, na.rm = TRUE)

# Set a threshold (e.g., 0.8) and identify low-coverage variables
threshold <- 0.8
low_coverage_vars <- names(coverage_means[coverage_means < threshold]) 
low_coverage_vars # "alcoholmodified" "bp_sys" "COMMUTE_PAEE" "v543m" 

## Keep "alcoholmodified" and "bp_sys" because else, factors only have one indicator

########## Adjusted model with variables with high coverage ########
####################################################################

#Adjusted model with removed "COMMUTE_PAEE" "v543m" 
CFA_Model2 <- 
  'Alcohol =~ alcoholmodified + v290m
  BMIf =~ BMIm
  Depression =~ HADS_depressionm+ HADSmodified+ v422m
  Diabetes =~ v377m
  Education =~ qualmodified + yearsedum
  Hearing =~ v336m+ v338m+ v339m+ v344m+ v345m+ v346m+ v347m+ v620m
  BP =~ v349m + bp_sys
  Cholesterol =~ v355m 
  PhysicalActivity =~ PAEE + HOME_PAEE + LEIS_PAEE + WORK_PAEE
  Smoking =~ smokermodified+ v241m+  v251m+ v259m+ v261m
  SocialIsolation =~ v5m+ v86+ v89+ v90m+ v91m+v92m+v93m+v94m+ v95m+ v96modified+ v97m+ v98m
  TBI =~ v457m+ v542m
  Vision =~ v328m+ v333modified+ v334modified+ v335modified+ v621m'


fit2 <- cfa(CFA_Model2, data = my_data_scaled, missing = "fiml", em.h1.iter.max = 10000, verbose = TRUE,  optim.method = "BFGS") 
summary(fit2, fit.measures = T, standardized = T) # Bad metrics

## Remove varibales with low Factor loadings (<0.3)
'
Physical Activity: HOME_PAEE, LEIS_PAEE, WORK_PAEE
Smoking: v259m, v261m
Social Isolation: v5m, v92m, v94m, v95m, v96modified, v97m, v98m
TBI: v457m and v542m (keep v457m to have at least 1 indicator)
Vision: v621m
'

######### Adjusted model with variables with llow factor loading ########
########################### MODEL USED FOR TABLE 1 ######################
#########################################################################

#Adjusted model with removed low factor loading
CFA_Model3 <- 
  'Alcohol =~ alcoholmodified + v290m
  BMIf =~ BMIm
  Depression =~ HADS_depressionm+ HADSmodified+ v422m
  Diabetes =~ v377m
  Education =~ qualmodified + yearsedum
  Hearing =~ v336m+ v338m+ v339m+ v344m+ v345m+ v346m+ v347m+ v620m
  BP =~ v349m + bp_sys
  Cholesterol =~ v355m 
  PhysicalActivity =~ PAEE 
  Smoking =~ smokermodified+ v241m+  v251m
  TBI =~ v457m
  SocialIsolation =~ v86+ v89+ v90m+ v91m+ v93m
  Vision =~ v328m+ v333modified+ v334modified+ v335modified'


fit3 <- cfa(CFA_Model3, data = my_data_scaled, missing = "fiml", em.h1.iter.max = 10000, verbose = TRUE,  optim.method = "BFGS") 
summary(fit3, fit.measures = T, standardized = T) # Good Metrics


####################### Covariance matrix ####################
##############################################################

my_data_scaleddf <- as.data.frame(my_data_scaled)
cor_cfa <- my_data_scaleddf %>%
  select(alcoholmodified, v290m, 
         BMIm, 
         HADS_depressionm, HADSmodified, v422m, 
         v377m,
         qualmodified, yearsedum,
         v336m, v338m, v339m, v344m, v345m, v346m, v347m, v620m,
         v349m, bp_sys,
         v355m,
         PAEE,
         smokermodified, v241m, v251m,
         v86, v89, v90m, v91m, v93m,
         v457m,
         v328m, v333modified, v334modified, v335modified)

cov_matrix_cfa <- cor(cor_cfa, use = "pairwise.complete.obs")
corrplot(cov_matrix_cfa, method = "color",  tl.col = "black", tl.cex = 0.7) ## Social facot is negatively correlated with all other varaiables


########################## Print Output #######################
###############################################################

##  Define variable
fitStat <- fitMeasures(fit3)
# Select and format the ones I want
fit_table <- data.frame(
  Measure = c("Chi-square", "Degrees of Freedom", "p-value", 
              "CFI", "TLI", 
              "RMSEA", "RMSEA 90% CI (lower)", "RMSEA 90% CI (upper)",
              "SRMR"),
  Value = round(fitStat[c("chisq", "df", "pvalue", 
                          "cfi", "tli", 
                          "rmsea", "rmsea.ci.lower", "rmsea.ci.upper", 
                          "srmr")], 3)
)

kable(fit_table, caption = "Model Fit Indices") %>%
  kable_styling(full_width = FALSE, position = "center")

####################################################################### EXPLORATORY FACTOR ANALYSIS ############################################################
################################################################################################################################################################

################# PREPARATION OF LIFESTYLE FACTORS ################
###################################################################

#Define Factor Scores
factor_scores <- lavPredict(fit3)

#turn into dataframe
factor_scores_df <- as.data.frame(factor_scores)


########## PCA for Lifestyle to determine number of factors ###########
#######################################################################
# Inspect NAs because PCA sensitive to it
sum(is.na(factor_scores_df)) # Count NAs #0

# Perform PCA
pca_result_ls <- prcomp(factor_scores_df, center = TRUE, scale. = TRUE)

# Variance explained
explained_ls <- summary(pca_result_ls)$importance[2, ] * 100  # Percent variance
cumulative_explained_ls <- summary(pca_result_ls)$importance[3, ] * 100 # cumulative
latent_ls <- pca_result_ls$sdev^2  # Eigenvalues

# Kaiser criterion (eigenvalue > 1)
nPC_ls <- sum(latent_ls * length(latent_ls) / sum(latent_ls) > 1)
print(nPC_ls)  # returns 5 - But factor 6 has Eigenvalue of 0.977

# Scree plot
fviz_eig(pca_result_ls, addlabels = TRUE)


################# Factor analysis for Lifestyle ################
################################################################

### 5 Factor solution
# Run factor analysis with 5 factors and varimax rotation
fa_result_5 <- fa(factor_scores_df, nfactors = 5, rotate = "varimax", fm = "ml")

# Print factor loadings
print(fa_result_5, cutoff = 0.1)

# Plot loadings
fa.diagram(fa_result_5)

### 6 Factor solution
# Run factor analysis with 5 factors and varimax rotation
fa_result_6 <- fa(factor_scores_df, nfactors = 6, rotate = "varimax", fm = "ml")

# Print factor loadings
print(fa_result_6, cutoff = 0.1)

######################### Presentations #####################
####################### BASIS FOR FIGURE 1 ##################
#############################################################

# Plot loadings Figure 1
fa.diagram(fa_result_6)


### Lifestyle
fit_table_efa <- data.frame(
  Measure = c("Chi-square", "Degrees of Freedom", "p-value", "TLI", "RMSEA", "BIC"),
  Value = round(c(fa_result_6$STATISTIC,
                  fa_result_6$dof,
                  fa_result_6$PVAL,
                  fa_result_6$TLI,
                  fa_result_6$RMSEA[1],   # RMSEA estimate is the first value
                  fa_result_6$BIC), 3)
)

kable(fit_table_efa, caption = "EFA Model Fit Indices") %>%
  kable_styling(full_width = FALSE, position = "center")


################# PCA for White Matter ################
#######################################################

# Matrix of WM scores
pca_WM <- num_data[, c( "CCIDmodified", "FA_mean","MSD_mean","MSK_mean","NDI_mean","ODI_mean","Fiso_mean")]
pca_WM <- pca_WM[!pca_WM$CCIDmodified %in% c("222120", "621199"), ]
pca_WMm <- pca_WM %>% select(-CCIDmodified)
fa_wm <- pca_WM %>% select(-CCIDmodified)
## Remove NA
pca_WM_clean <- pca_WMm[complete.cases(pca_WMm) & apply(pca_WMm, 1, function(x) all(is.finite(x))), ]
sum(is.na(pca_WM_clean))# Count NAs #528
nrow(pca_WM) #618 / 88 removed

# Perform PCA
pca_result_wm <- prcomp(pca_WM_clean, center = TRUE, scale. = TRUE)

# Variance explained
explained <- summary(pca_result_wm)$importance[2, ] * 100  # Percent variance #Pretty differnt from Henriques
latent <- pca_result_wm$sdev^2  # Eigenvalues

# Kaiser criterion (eigenvalue > 1)
nPC_wm <- sum(latent * length(latent) / sum(latent) > 1)
print(nPC_wm)  # Should return 3 but returns 2

# Scree plot
fviz_eig(pca_result_wm, addlabels = TRUE)


######################### Inspect missings ###############
##########################################################

colSums(is.na(my_data_scaled))
sum(!complete.cases(my_data_scaled))
sum(complete.cases(my_data_scaled))

'
Total= 34 * 706 = 24004
Missings (only of 34 included variables): 160+122+2+2+4+6+1+1+3+4+2+3+4+1+4+4+128+5+83+2+57+0+0+0+10+10+5+0
Sum= 623
Potion of total= 623 / 24004 = 0.0259 = 2.6%
'


##################### FA for White Matter ##################
###################### BASIS OF FIGURE 2 ###################
############################################################

# Run factor analysis with 3 factors and varimax rotation
fa_result_wm <- fa(fa_wm, nfactors = 3, rotate = "varimax", fm = "ml")

# Print factor loadings
print(fa_result_wm$loadings, cutoff = 0.3)

#Plot loadings
fa.diagram(fa_result_wm)


mean(fa_result_wm$communality)

########### Combine the factor loadings into the data ########
##############################################################

# Bind lifestyle factor scores to original data
df_cleanp_scaled <- scale(df_cleanp)
ls_loadings_df <- as.data.frame(fa_result_6$scores)
data_efa_ls <- cbind(df_cleanp_scaled, ls_loadings_df)

#Export WM to Table 
wm_loadings_df <- as.data.frame(fa_result_wm$scores)
colnames(wm_loadings_df) # Change names so ML1 etc are no duplicates when binding dfs
wm_loadings_df$WM1 <- wm_loadings_df$ML1
wm_loadings_df$WM2 <- wm_loadings_df$ML2
wm_loadings_df$WM3 <- wm_loadings_df$ML3
# remove previous columns
wm_loadings_df <- wm_loadings_df %>% select(-ML1, -ML2, -ML3)

# Bind WM factor scores to original data
data_efa_tot <- cbind(data_efa_ls, wm_loadings_df)


############# Cognition computation ###############
####################################################

num_data <- num_data[!num_data$CCIDmodified %in% c("222120", "621199"), ]
cognition <- num_data %>%
  select( C1.y,C2.y,C3.y,C4.y
  )

## Factor analysis
# Run factor analysis with 1 factor for cognition (IQ) and varimax rotation
cog_result <- fa(cognition, nfactors = 1, rotate = "varimax", fm = "ml")

# Print factor loadings
print(cog_result$loadings, cutoff = 0.3)
mean(cog_result$communality)

#Export to Table
cog_loadings_df <- as.data.frame(cog_result$scores)
cog_loadings_df$COG <- cog_loadings_df$ML1


###################################################################### Correlations for SEM  ###################################################################
################################################################################################################################################################


############# Create Dataframe for Correlations ###############
###############################################################

#### Dataframes solely, with the factor loadings
## WM
wm_data <- data_efa_tot %>%
  select(WM1, WM2)

## Lifestyle
ls_data <- data_efa_tot %>%
  select( ML1, ML2, ML3, ML4, ML5, ML6)

## Cognition
cog_data <- cog_loadings_df %>%
  select(COG)

##### Factor Loadings into 1 dataset ####
cor_data  <- cbind(wm_data, cog_data, ls_data)
colnames(cor_data)

sapply(cor_data, class) 

######################## Correlations #########################
###############################################################

vars <- colnames(cor_data)
n <- length(vars)

# Empty matrices to store results
cor_mat <- matrix(NA, n, n, dimnames = list(vars, vars))
p_mat <- matrix(NA, n, n, dimnames = list(vars, vars))

# Loop through variable pairs
for (i in 1:n) {
  for (j in i:n) {
    test <- cor.test(cor_data[[i]], cor_data[[j]], method = "pearson")
    cor_mat[i, j] <- test$estimate
    cor_mat[j, i] <- test$estimate
    p_mat[i, j] <- test$p.value
    p_mat[j, i] <- test$p.value
  }
}
## Double check symmetry
all.equal(p_mat, t(p_mat))


############################# Viszualize #######################
####################### BASIS FOR FIGURE 3 #####################
################################################################

#Create a matrix of significance stars
stars_matrix <- ifelse(p_mat < 0.001, "***",
                       ifelse(p_mat < 0.01, "**",
                              ifelse(p_mat < 0.05, "*", "")))

# Melt matrices to long format
corr_melt <- melt(cor_mat)
stars_melt <- melt(stars_matrix)

# Combine into one dataframe
corr_plot_data <- merge(corr_melt, stars_melt, by = c("Var1", "Var2"))
colnames(corr_plot_data) <- c("Var1", "Var2", "Correlation", "Significance")
corr_plot_data <- corr_plot_data[corr_plot_data$Var1 != corr_plot_data$Var2, ]

# Remove selected pairs
excluded_pairs <- list(
  c("ML1", "ML2"),
  c("ML1", "ML3"),
  c("ML1", "ML4"),
  c("ML1", "ML5"),
  c("ML1", "ML6"),
  c("ML2", "ML3"),
  c("ML2", "ML4"),
  c("ML2", "ML5"),
  c("ML2", "ML6"),
  c("ML3", "ML4"),
  c("ML3", "ML5"),
  c("ML3", "ML6"),
  c("ML4", "ML5"),
  c("ML4", "ML6"),
  c("ML5", "ML6"),
  c("WM2", "WM1"),
  c("ML6", "ML5"),
  c("ML6", "ML4"),
  c("ML6", "ML3"),
  c("ML6", "ML2"),
  c("ML6", "ML1"),
  c("ML5", "ML4"),
  c("ML5", "ML3"),
  c("ML5", "ML2"),
  c("ML5", "ML1"),
  c("ML4", "ML3"),
  c("ML4", "ML2"),
  c("ML4", "ML1"),
  c("ML3", "ML2"),
  c("ML3", "ML1"),
  c("ML2", "ML1"),
  c("WM1", "WM2")
)
corr_plot_data <- corr_plot_data[!mapply(function(v1, v2) {
  any(mapply(function(pair) all(c(v1, v2) == pair), excluded_pairs))
}, corr_plot_data$Var1, corr_plot_data$Var2), ]

# reorder
desired_order <- c("ML6", "ML5", "ML4","ML3","ML2","ML1","WM2","WM1", "COG")
corr_plot_data$Var1 <- factor(corr_plot_data$Var1, levels = desired_order)
corr_plot_data$Var2 <- factor(corr_plot_data$Var2, levels = desired_order)
# Remove diagonal
corr_plot_data <- corr_plot_data[corr_plot_data$Var1 != corr_plot_data$Var2, ]

# Remove lower triangle (keep only upper triangle)
corr_plot_data <- corr_plot_data[
  match(corr_plot_data$Var1, desired_order) <
    match(corr_plot_data$Var2, desired_order), ]

######### FIGURE 3A

# Plot using ggplot2
ggplot(corr_plot_data, aes(x = Var1, y = Var2, fill = Correlation)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(low = "skyblue", mid = "white", high = "hotpink", midpoint = 0,
                       limits = c(-1, 1), name = "r") +
  geom_text(aes(label = paste0(round(Correlation, 2), Significance)), size = 4) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        panel.grid = element_blank()) +
  labs(title = "Correlation Matrix with Significance", x = "", y = "")


########### Network visualization

# Filter: remove weak or nonsignificant correlations
cor_filtered <- cor_mat
cor_filtered[p_mat > 0.05] <- 0  # threshold example

# Remove self-correlations (diagonal)
diag(cor_filtered) <- 0

# Optional: remove specific variable pairs
cor_filtered["ML1", "ML2"] <- 0
cor_filtered["ML1", "ML3"] <- 0
cor_filtered["ML1", "ML4"] <- 0
cor_filtered["ML1", "ML5"] <- 0
cor_filtered["ML1", "ML6"] <- 0
cor_filtered["ML2", "ML3"] <- 0
cor_filtered["ML2", "ML4"] <- 0
cor_filtered["ML2", "ML5"] <- 0
cor_filtered["ML2", "ML6"] <- 0
cor_filtered["ML3", "ML4"] <- 0
cor_filtered["ML3", "ML5"] <- 0
cor_filtered["ML3", "ML6"] <- 0
cor_filtered["ML4", "ML5"] <- 0
cor_filtered["ML4", "ML6"] <- 0
cor_filtered["ML5", "ML6"] <- 0
cor_filtered["WM2", "WM1"] <- 0
cor_filtered["ML6", "ML5"] <- 0
cor_filtered["ML6", "ML4"] <- 0
cor_filtered["ML6", "ML3"] <- 0
cor_filtered["ML6", "ML2"] <- 0
cor_filtered["ML6", "ML1"] <- 0
cor_filtered["ML5", "ML4"] <- 0
cor_filtered["ML5", "ML3"] <- 0
cor_filtered["ML5", "ML2"] <- 0
cor_filtered["ML5", "ML1"] <- 0
cor_filtered["ML4", "ML3"] <- 0
cor_filtered["ML4", "ML2"] <- 0
cor_filtered["ML4", "ML1"] <- 0
cor_filtered["ML3", "ML2"] <- 0
cor_filtered["ML3", "ML1"] <- 0
cor_filtered["ML2", "ML1"] <- 0
cor_filtered["WM1", "WM2"] <- 0

col_fun = colorRamp2(range(cor_filtered), c("skyblue", "hotpink"), transparency = 0.3)

######### FIGURE 3B

# Create the chord diagram
chordDiagram(
  cor_filtered,
  symmetric = TRUE,
  grid.col = "darkgray", 
  col = col_fun,
  annotationTrack = c("name", "grid")
)


#################################### PREP DATA FOR SEM ##########################
#################################################################################

#Prep Age
age <- num_data$Age
age2 <- poly(age, 2)
age2 <- as.data.frame(age2)
age2$agelin <- age2[, "1"]
age2$agequad <- age2[, "2"]
colnames(age2)

#Prep Sex
sex <- num_data %>%
  select( sex, CCIDmodified)
sexc <- sex[!num_data$CCIDmodified %in% c("222120", "621199"), ]
sexc <- sexc[, !(names(sexc) %in% "CCIDmodified")]

## 
data_sem_sex <- cbind(cor_data, age2, sex)


### PRINT DATA FOR ANALYSES
write.csv(data_sem_sex, "data_sem_fig4.csv")
